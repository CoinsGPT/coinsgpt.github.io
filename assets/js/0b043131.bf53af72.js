"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([["56601"],{57234:function(e,n,s){s.d(n,{Z:()=>o});let o=s.p+"assets/images/bitcoin_data_pipeline-083bc34cccd93411924337896b88770f.png"},66840:function(e,n,s){s.r(n),s.d(n,{frontMatter:()=>i,default:()=>h,contentTitle:()=>c,assets:()=>a,toc:()=>l,metadata:()=>o});var o=JSON.parse('{"id":"bitcoin/kafka-setup","title":"03 Create Kafka Topics and Consumer Groups","description":"In this guide, we\u2019ll simulate a use case for managing Bitcoin-related streaming data using Apache Kafka. We\'ll cover how to create topics, manage consumers, observe consumption status, and configure retention policies.","source":"@site/docs/bitcoin/kafka-setup.md","sourceDirName":"bitcoin","slug":"/bitcoin/kafka-setup","permalink":"/docs/next/bitcoin/kafka-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/coinsgpt/coinsgpt.github.io/edit/main/website/docs/bitcoin/kafka-setup.md","tags":[],"version":"current","lastUpdatedBy":"Gitcoins","lastUpdatedAt":1752593414000,"frontMatter":{},"sidebar":"bitcoin","previous":{"title":"02 Stream Raw Data with ETL","permalink":"/docs/next/bitcoin/bitcoin-etl"},"next":{"title":"04 ClickHouse Setup","permalink":"/docs/next/bitcoin/clickhouse-setup"}}'),r=s(85893),t=s(80980);let i={},c="03 Create Kafka Topics and Consumer Groups",a={},l=[{value:"Scenario: Stream Bitcoin Blocks and Transactions",id:"scenario-stream-bitcoin-blocks-and-transactions",level:2},{value:"0. Common Command",id:"0-common-command",level:2},{value:"1. Create Kafka Topics",id:"1-create-kafka-topics",level:2},{value:"2. Produce and Consume Messages",id:"2-produce-and-consume-messages",level:2},{value:"3. Create and Use Consumer Groups",id:"3-create-and-use-consumer-groups",level:2},{value:"4. Monitor Consumer Groups",id:"4-monitor-consumer-groups",level:2},{value:"5. Configure Log Retention (to prevent disk overflow)",id:"5-configure-log-retention-to-prevent-disk-overflow",level:2},{value:"6. Enlarge Topic Max Message",id:"6-enlarge-topic-max-message",level:2},{value:"7. Describe a Kafka Topic (to check configs)",id:"7-describe-a-kafka-topic-to-check-configs",level:2},{value:"Summary",id:"summary",level:2}];function d(e){let n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.a)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"03-create-kafka-topics-and-consumer-groups",children:"03 Create Kafka Topics and Consumer Groups"})}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.img,{src:s(57234).Z+"",width:"1536",height:"1024"})}),"\n",(0,r.jsxs)(n.p,{children:["In this guide, we\u2019ll simulate a use case for managing Bitcoin-related streaming data using ",(0,r.jsx)(n.strong,{children:"Apache Kafka"}),". We'll cover how to create topics, manage consumers, observe consumption status, and configure retention policies."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"scenario-stream-bitcoin-blocks-and-transactions",children:"Scenario: Stream Bitcoin Blocks and Transactions"}),"\n",(0,r.jsx)(n.p,{children:"You\u2019re building a Kafka-based data pipeline for Bitcoin. You\u2019ll:"}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:["Create Kafka topics: ",(0,r.jsx)(n.code,{children:"blocks"})," and ",(0,r.jsx)(n.code,{children:"transactions"})]}),"\n",(0,r.jsx)(n.li,{children:"Create consumer groups automatically"}),"\n",(0,r.jsx)(n.li,{children:"Produce and consume messages"}),"\n",(0,r.jsx)(n.li,{children:"Monitor consumer lags"}),"\n",(0,r.jsx)(n.li,{children:"Set log retention policies to prevent disk overflow"}),"\n"]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"0-common-command",children:"0. Common Command"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-consumer-groups.sh \\\n  --describe \\\n  --group bitcoin-group \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,r.jsx)(n.h2,{id:"1-create-kafka-topics",children:"1. Create Kafka Topics"}),"\n",(0,r.jsxs)(n.p,{children:["Topics are the core abstraction for message streams. You create them using ",(0,r.jsx)(n.code,{children:"kafka-topics.sh"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-topics.sh \\\n  --create \\\n  --topic blocks \\\n  --bootstrap-server localhost:9092 \\\n  --partitions 3 \\\n  --replication-factor 1\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-topics.sh \\\n  --create \\\n  --topic transactions \\\n  --bootstrap-server localhost:9092 \\\n  --partitions 3 \\\n  --replication-factor 1\n"})}),"\n",(0,r.jsx)(n.p,{children:"Verify that the topics were created:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-topics.sh \\\n  --list \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,r.jsx)(n.h2,{id:"2-produce-and-consume-messages",children:"2. Produce and Consume Messages"}),"\n",(0,r.jsx)(n.p,{children:"Produce messages into a topic:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-console-producer.sh \\\n  --topic transactions \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,r.jsx)(n.p,{children:"Type messages in the terminal after this command runs."}),"\n",(0,r.jsx)(n.p,{children:"Consume messages from the beginning:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-console-consumer.sh \\\n  --topic transactions \\\n  --from-beginning \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,r.jsx)(n.h2,{id:"3-create-and-use-consumer-groups",children:"3. Create and Use Consumer Groups"}),"\n",(0,r.jsxs)(n.p,{children:["Consumer groups are created ",(0,r.jsx)(n.strong,{children:"implicitly"})," when a consumer subscribes to a topic with a unique ",(0,r.jsx)(n.code,{children:"--group"}),"."]}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic blocks \\\n  --group bitcoin-group\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic transactions \\\n  --group bitcoin-group\n"})}),"\n",(0,r.jsxs)(n.p,{children:["Now the group ",(0,r.jsx)(n.code,{children:"bitcoin-group"})," is created and tracks offsets for each consumer."]}),"\n",(0,r.jsx)(n.hr,{}),"\n",(0,r.jsx)(n.h2,{id:"4-monitor-consumer-groups",children:"4. Monitor Consumer Groups"}),"\n",(0,r.jsx)(n.p,{children:"List all consumer groups:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-consumer-groups.sh \\\n  --bootstrap-server localhost:9092 \\\n  --list\n"})}),"\n",(0,r.jsx)(n.p,{children:"Describe group state (offsets, lag, assignments):"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-consumer-groups.sh \\\n  --describe \\\n  --group bitcoin-group \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,r.jsx)(n.p,{children:"Sample Output:"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"TOPIC       PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID     HOST             CLIENT-ID\nblocks      0          120             150             30   consumer-1-xyz  /192.168.0.2     consumer-1\ntransactions 1         110             140             30   consumer-1-xyz  /192.168.0.2     consumer-1\n"})}),"\n",(0,r.jsx)(n.h2,{id:"5-configure-log-retention-to-prevent-disk-overflow",children:"5. Configure Log Retention (to prevent disk overflow)"}),"\n",(0,r.jsx)(n.p,{children:"You can configure how long Kafka retains messages or how much disk space it uses per topic."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Set retention to 1 day and max 1GB per partition for 'blocks'\nkafka-configs.sh \\\n  --bootstrap-server localhost:9092 \\\n  --entity-type topics \\\n  --entity-name blocks \\\n  --alter \\\n  --add-config retention.ms=86400000,retention.bytes=1073741824,cleanup.policy=delete\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Same for 'transactions'\nkafka-configs.sh \\\n  --bootstrap-server localhost:9092 \\\n  --entity-type topics \\\n  --entity-name transactions \\\n  --alter \\\n  --add-config retention.ms=86400000,retention.bytes=1073741824,cleanup.policy=delete\n"})}),"\n",(0,r.jsx)(n.p,{children:"Explanation:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"retention.ms=86400000"}),": retain messages for 1 day."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"retention.bytes=1073741824"}),": max 1 GB per partition."]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.code,{children:"cleanup.policy=delete"}),": delete old segments (default behavior)."]}),"\n"]}),"\n",(0,r.jsxs)(n.blockquote,{children:["\n",(0,r.jsxs)(n.p,{children:["Kafka will delete log segments when ",(0,r.jsx)(n.strong,{children:"either"})," of the conditions is met."]}),"\n"]}),"\n",(0,r.jsx)(n.h2,{id:"6-enlarge-topic-max-message",children:"6. Enlarge Topic Max Message"}),"\n",(0,r.jsx)(n.p,{children:"Apache Kafka has several key limitations and configurable constraints that impact how much data can be produced, buffered, and consumed. Here's a clear breakdown of the main types of limitations:"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsx)(n.li,{children:"Message Size Limitations"}),"\n",(0,r.jsx)(n.li,{children:"Buffering & Memory Limits"}),"\n",(0,r.jsx)(n.li,{children:"Log & Retention Limits"}),"\n",(0,r.jsx)(n.li,{children:"Consumer Fetch & Processing Limits"}),"\n",(0,r.jsx)(n.li,{children:"Connection & Network Limits"}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["To ",(0,r.jsxs)(n.strong,{children:["enlarge your Kafka topic ",(0,r.jsx)(n.code,{children:"transactions"})," to support messages up to 90MB"]}),", you must:"]}),"\n",(0,r.jsxs)(n.ol,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Update the topic"})," config (",(0,r.jsx)(n.code,{children:"max.message.bytes"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Update the broker"})," config (",(0,r.jsx)(n.code,{children:"message.max.bytes"})," and ",(0,r.jsx)(n.code,{children:"replica.fetch.max.bytes"}),")"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Update your producer"})," config (",(0,r.jsx)(n.code,{children:"max.request.size"}),", ",(0,r.jsx)(n.code,{children:"buffer.memory"}),")"]}),"\n"]}),"\n",(0,r.jsx)(n.p,{children:"It works after finish the first step to update the transactions topic config."}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-configs.sh --bootstrap-server localhost:9092 \\\n  --entity-type topics \\\n  --entity-name transactions \\\n  --alter \\\n  --add-config max.message.bytes=94371840\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"kafka-configs.sh --bootstrap-server localhost:9092   --entity-type topics --entity-name transactions   --describe\n"})}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{children:"Dynamic configs for topic transactions are:\n  cleanup.policy=delete sensitive=false synonyms={DYNAMIC_TOPIC_CONFIG:cleanup.policy=delete, DEFAULT_CONFIG:log.cleanup.policy=delete}\n  max.message.bytes=94371840 sensitive=false synonyms={DYNAMIC_TOPIC_CONFIG:max.message.bytes=94371840, DEFAULT_CONFIG:message.max.bytes=1048588}\n  retention.bytes=1073741824 sensitive=false synonyms={DYNAMIC_TOPIC_CONFIG:retention.bytes=1073741824, DEFAULT_CONFIG:log.retention.bytes=-1}\n  retention.ms=86400000 sensitive=false synonyms={DYNAMIC_TOPIC_CONFIG:retention.ms=86400000}\n"})}),"\n",(0,r.jsx)(n.h2,{id:"7-describe-a-kafka-topic-to-check-configs",children:"7. Describe a Kafka Topic (to check configs)"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# View details of the 'transactions' topic\nkafka-topics.sh \\\n  --describe \\\n  --topic transactions \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,r.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,r.jsxs)(n.table,{children:[(0,r.jsx)(n.thead,{children:(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.th,{children:"Task"}),(0,r.jsx)(n.th,{children:"Command"})]})}),(0,r.jsxs)(n.tbody,{children:[(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Create topic"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-topics.sh --create"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"List topics"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-topics.sh --list"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Describe topic"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-topics.sh --describe"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Produce message"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-console-producer.sh"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Consume message"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-console-consumer.sh"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Use consumer group"}),(0,r.jsxs)(n.td,{children:[(0,r.jsx)(n.code,{children:"--group my-group"})," on consumer"]})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"List consumer groups"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-consumer-groups.sh --list"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Describe consumer group"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-consumer-groups.sh --describe --group my-group"})})]}),(0,r.jsxs)(n.tr,{children:[(0,r.jsx)(n.td,{children:"Configure topic retention"}),(0,r.jsx)(n.td,{children:(0,r.jsx)(n.code,{children:"kafka-configs.sh --alter --add-config"})})]})]})]})]})}function h(e={}){let{wrapper:n}={...(0,t.a)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(d,{...e})}):d(e)}},80980:function(e,n,s){s.d(n,{Z:()=>c,a:()=>i});var o=s(67294);let r={},t=o.createContext(r);function i(e){let n=o.useContext(t);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),o.createElement(t.Provider,{value:n},e.children)}}}]);