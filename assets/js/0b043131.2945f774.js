"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([["56601"],{57234:function(e,n,s){s.d(n,{Z:()=>o});let o=s.p+"assets/images/bitcoin_data_pipeline-083bc34cccd93411924337896b88770f.png"},66840:function(e,n,s){s.r(n),s.d(n,{frontMatter:()=>i,default:()=>h,contentTitle:()=>c,assets:()=>a,toc:()=>l,metadata:()=>o});var o=JSON.parse('{"id":"bitcoin/kafka-setup","title":"03 Create Kafka Topics and Consumer Groups","description":"In this guide, we\u2019ll simulate a use case for managing Bitcoin-related streaming data using Apache Kafka. We\'ll cover how to create topics, manage consumers, observe consumption status, and configure retention policies.","source":"@site/docs/bitcoin/kafka-setup.md","sourceDirName":"bitcoin","slug":"/bitcoin/kafka-setup","permalink":"/docs/next/bitcoin/kafka-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/coinsgpt/coinsgpt.github.io/edit/main/website/docs/bitcoin/kafka-setup.md","tags":[],"version":"current","lastUpdatedBy":"thebestornothing","lastUpdatedAt":1748571791000,"frontMatter":{},"sidebar":"bitcoin","previous":{"title":"02 Stream Raw Data with ETL","permalink":"/docs/next/bitcoin/bitcoin-etl"},"next":{"title":"04 ClickHouse Setup","permalink":"/docs/next/bitcoin/clickhouse-setup"}}'),t=s(85893),r=s(80980);let i={},c="03 Create Kafka Topics and Consumer Groups",a={},l=[{value:"Scenario: Stream Bitcoin Blocks and Transactions",id:"scenario-stream-bitcoin-blocks-and-transactions",level:2},{value:"1. Create Kafka Topics",id:"1-create-kafka-topics",level:2},{value:"2. Produce and Consume Messages",id:"2-produce-and-consume-messages",level:2},{value:"3. Create and Use Consumer Groups",id:"3-create-and-use-consumer-groups",level:2},{value:"4. Monitor Consumer Groups",id:"4-monitor-consumer-groups",level:2},{value:"5. Configure Log Retention (to prevent disk overflow)",id:"5-configure-log-retention-to-prevent-disk-overflow",level:2},{value:"6. Describe a Kafka Topic (to check configs)",id:"6-describe-a-kafka-topic-to-check-configs",level:2},{value:"Summary",id:"summary",level:2}];function d(e){let n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,r.a)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"03-create-kafka-topics-and-consumer-groups",children:"03 Create Kafka Topics and Consumer Groups"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.img,{src:s(57234).Z+"",width:"1536",height:"1024"})}),"\n",(0,t.jsxs)(n.p,{children:["In this guide, we\u2019ll simulate a use case for managing Bitcoin-related streaming data using ",(0,t.jsx)(n.strong,{children:"Apache Kafka"}),". We'll cover how to create topics, manage consumers, observe consumption status, and configure retention policies."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"scenario-stream-bitcoin-blocks-and-transactions",children:"Scenario: Stream Bitcoin Blocks and Transactions"}),"\n",(0,t.jsx)(n.p,{children:"You\u2019re building a Kafka-based data pipeline for Bitcoin. You\u2019ll:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:["Create Kafka topics: ",(0,t.jsx)(n.code,{children:"blocks"})," and ",(0,t.jsx)(n.code,{children:"transactions"})]}),"\n",(0,t.jsx)(n.li,{children:"Create consumer groups automatically"}),"\n",(0,t.jsx)(n.li,{children:"Produce and consume messages"}),"\n",(0,t.jsx)(n.li,{children:"Monitor consumer lags"}),"\n",(0,t.jsx)(n.li,{children:"Set log retention policies to prevent disk overflow"}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"1-create-kafka-topics",children:"1. Create Kafka Topics"}),"\n",(0,t.jsxs)(n.p,{children:["Topics are the core abstraction for message streams. You create them using ",(0,t.jsx)(n.code,{children:"kafka-topics.sh"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Create the 'blocks' topic with 3 partitions and replication factor 1\nkafka-topics.sh \\\n  --create \\\n  --topic blocks \\\n  --bootstrap-server localhost:9092 \\\n  --partitions 3 \\\n  --replication-factor 1\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Create the 'transactions' topic with 3 partitions and replication factor 1\nkafka-topics.sh \\\n  --create \\\n  --topic transactions \\\n  --bootstrap-server localhost:9092 \\\n  --partitions 3 \\\n  --replication-factor 1\n"})}),"\n",(0,t.jsx)(n.p,{children:"Verify that the topics were created:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# List all existing Kafka topics\nkafka-topics.sh \\\n  --list \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,t.jsx)(n.h2,{id:"2-produce-and-consume-messages",children:"2. Produce and Consume Messages"}),"\n",(0,t.jsx)(n.p,{children:"Produce messages into a topic:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Start a producer to the 'transactions' topic\nkafka-console-producer.sh \\\n  --topic transactions \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,t.jsx)(n.p,{children:"Type messages in the terminal after this command runs."}),"\n",(0,t.jsx)(n.p,{children:"Consume messages from the beginning:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Start a consumer to read all messages from the beginning of the topic\nkafka-console-consumer.sh \\\n  --topic transactions \\\n  --from-beginning \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,t.jsx)(n.h2,{id:"3-create-and-use-consumer-groups",children:"3. Create and Use Consumer Groups"}),"\n",(0,t.jsxs)(n.p,{children:["Consumer groups are created ",(0,t.jsx)(n.strong,{children:"implicitly"})," when a consumer subscribes to a topic with a unique ",(0,t.jsx)(n.code,{children:"--group"}),"."]}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Consume from 'blocks' with consumer group 'bitcoin-group'\nkafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic blocks \\\n  --group bitcoin-group\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Consume from 'transactions' with the same group\nkafka-console-consumer.sh \\\n  --bootstrap-server localhost:9092 \\\n  --topic transactions \\\n  --group bitcoin-group\n"})}),"\n",(0,t.jsxs)(n.p,{children:["Now the group ",(0,t.jsx)(n.code,{children:"bitcoin-group"})," is created and tracks offsets for each consumer."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h2,{id:"4-monitor-consumer-groups",children:"4. Monitor Consumer Groups"}),"\n",(0,t.jsx)(n.p,{children:"List all consumer groups:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kafka-consumer-groups.sh \\\n  --bootstrap-server localhost:9092 \\\n  --list\n"})}),"\n",(0,t.jsx)(n.p,{children:"Describe group state (offsets, lag, assignments):"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"kafka-consumer-groups.sh \\\n  --describe \\\n  --group bitcoin-group \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,t.jsx)(n.p,{children:"Sample Output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"TOPIC       PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID     HOST             CLIENT-ID\nblocks      0          120             150             30   consumer-1-xyz  /192.168.0.2     consumer-1\ntransactions 1         110             140             30   consumer-1-xyz  /192.168.0.2     consumer-1\n"})}),"\n",(0,t.jsx)(n.h2,{id:"5-configure-log-retention-to-prevent-disk-overflow",children:"5. Configure Log Retention (to prevent disk overflow)"}),"\n",(0,t.jsx)(n.p,{children:"You can configure how long Kafka retains messages or how much disk space it uses per topic."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Set retention to 1 day and max 1GB per partition for 'blocks'\nkafka-configs.sh \\\n  --bootstrap-server localhost:9092 \\\n  --entity-type topics \\\n  --entity-name blocks \\\n  --alter \\\n  --add-config retention.ms=86400000,retention.bytes=1073741824,cleanup.policy=delete\n"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# Same for 'transactions'\nkafka-configs.sh \\\n  --bootstrap-server localhost:9092 \\\n  --entity-type topics \\\n  --entity-name transactions \\\n  --alter \\\n  --add-config retention.ms=86400000,retention.bytes=1073741824,cleanup.policy=delete\n"})}),"\n",(0,t.jsx)(n.p,{children:"Explanation:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"retention.ms=86400000"}),": retain messages for 1 day."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"retention.bytes=1073741824"}),": max 1 GB per partition."]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.code,{children:"cleanup.policy=delete"}),": delete old segments (default behavior)."]}),"\n"]}),"\n",(0,t.jsxs)(n.blockquote,{children:["\n",(0,t.jsxs)(n.p,{children:["Kafka will delete log segments when ",(0,t.jsx)(n.strong,{children:"either"})," of the conditions is met."]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"6-describe-a-kafka-topic-to-check-configs",children:"6. Describe a Kafka Topic (to check configs)"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-bash",children:"# View details of the 'transactions' topic\nkafka-topics.sh \\\n  --describe \\\n  --topic transactions \\\n  --bootstrap-server localhost:9092\n"})}),"\n",(0,t.jsx)(n.h2,{id:"summary",children:"Summary"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,t.jsxs)(n.table,{children:[(0,t.jsx)(n.thead,{children:(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.th,{children:"Task"}),(0,t.jsx)(n.th,{children:"Command"})]})}),(0,t.jsxs)(n.tbody,{children:[(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Create topic"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-topics.sh --create"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"List topics"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-topics.sh --list"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Describe topic"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-topics.sh --describe"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Produce message"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-console-producer.sh"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Consume message"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-console-consumer.sh"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Use consumer group"}),(0,t.jsxs)(n.td,{children:[(0,t.jsx)(n.code,{children:"--group my-group"})," on consumer"]})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"List consumer groups"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-consumer-groups.sh --list"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Describe consumer group"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-consumer-groups.sh --describe --group my-group"})})]}),(0,t.jsxs)(n.tr,{children:[(0,t.jsx)(n.td,{children:"Configure topic retention"}),(0,t.jsx)(n.td,{children:(0,t.jsx)(n.code,{children:"kafka-configs.sh --alter --add-config"})})]})]})]})]})}function h(e={}){let{wrapper:n}={...(0,r.a)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},80980:function(e,n,s){s.d(n,{Z:()=>c,a:()=>i});var o=s(67294);let t={},r=o.createContext(t);function i(e){let n=o.useContext(r);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:i(e.components),o.createElement(r.Provider,{value:n},e.children)}}}]);