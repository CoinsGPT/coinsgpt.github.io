"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([["20376"],{57234:function(n,t,i){i.d(t,{Z:()=>s});let s=i.p+"assets/images/bitcoin_data_pipeline-083bc34cccd93411924337896b88770f.png"},20332:function(n,t,i){i.r(t),i.d(t,{frontMatter:()=>r,default:()=>h,contentTitle:()=>a,assets:()=>c,toc:()=>l,metadata:()=>s});var s=JSON.parse('{"id":"bitcoin/clickhouse-data-sync","title":"04 ClickHouse Data Sync","description":"Data Verification & Synchronization Checklist held in ClickHOuse. Before executing clickhousesyncdata.py, follow this academic-grade process:","source":"@site/docs/bitcoin/clickhouse-data-sync.md","sourceDirName":"bitcoin","slug":"/bitcoin/clickhouse-data-sync","permalink":"/docs/next/bitcoin/clickhouse-data-sync","draft":false,"unlisted":false,"editUrl":"https://github.com/coinsgpt/coinsgpt.github.io/edit/main/website/docs/bitcoin/clickhouse-data-sync.md","tags":[],"version":"current","lastUpdatedBy":"Gitcoins","lastUpdatedAt":1752593414000,"frontMatter":{},"sidebar":"bitcoin","previous":{"title":"05 Bitcoin Data Consistency","permalink":"/docs/next/bitcoin/bitcoin-data-consistency"},"next":{"title":"05 ClickHouse Kafka Engine","permalink":"/docs/next/bitcoin/clickhouse-table-engine"}}'),e=i(85893),o=i(80980);let r={},a="04 ClickHouse Data Sync",c={},l=[];function p(n){let t={a:"a",code:"code",h1:"h1",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,o.a)(),...n.components};return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsx)(t.header,{children:(0,e.jsx)(t.h1,{id:"04-clickhouse-data-sync",children:"04 ClickHouse Data Sync"})}),"\n",(0,e.jsx)(t.p,{children:(0,e.jsx)(t.img,{src:i(57234).Z+"",width:"1536",height:"1024"})}),"\n",(0,e.jsxs)(t.p,{children:["Data Verification & Synchronization Checklist held in ClickHOuse. Before executing ",(0,e.jsx)(t.a,{href:"https://github.com/TheBestOrNothing/bitcoin-etl/blob/master/bitcoinetl/cli/clickhouse_sync_data.py",children:(0,e.jsx)(t.code,{children:"clickhouse_sync_data.py"})}),", follow this academic-grade process:"]}),"\n",(0,e.jsxs)(t.ol,{children:["\n",(0,e.jsxs)(t.li,{children:["\n",(0,e.jsxs)(t.p,{children:[(0,e.jsx)(t.strong,{children:"Inspect the partitions"})," in ",(0,e.jsx)(t.code,{children:"blocks_fat"})," and ",(0,e.jsx)(t.code,{children:"transactions_fat"}),"."]}),"\n",(0,e.jsxs)(t.ul,{children:["\n",(0,e.jsx)(t.li,{children:"Query min/max block numbers per partition."}),"\n",(0,e.jsx)(t.li,{children:"Check for duplicate or orphaned entries."}),"\n"]}),"\n"]}),"\n",(0,e.jsxs)(t.li,{children:["\n",(0,e.jsxs)(t.p,{children:["Run ",(0,e.jsx)(t.a,{href:"https://github.com/TheBestOrNothing/bitcoin-etl/blob/master/bitcoinetl/cli/clickhouse_block_hole_finding.py",children:(0,e.jsx)(t.code,{children:"clickhouse_block_hole_finding.py"})})]}),"\n",(0,e.jsxs)(t.ul,{children:["\n",(0,e.jsx)(t.li,{children:"Identify gaps in block sequence."}),"\n",(0,e.jsx)(t.li,{children:"Save results to a log or CSV."}),"\n"]}),"\n"]}),"\n",(0,e.jsxs)(t.li,{children:["\n",(0,e.jsxs)(t.p,{children:["Run ",(0,e.jsx)(t.a,{href:"https://github.com/TheBestOrNothing/bitcoin-etl/blob/master/bitcoinetl/cli/clickhouse_block_hole_fixing.py",children:(0,e.jsx)(t.code,{children:"clickhouse_block_hole_fixing.py"})})]}),"\n",(0,e.jsxs)(t.ul,{children:["\n",(0,e.jsx)(t.li,{children:"Backfill missing blocks."}),"\n",(0,e.jsx)(t.li,{children:"Confirm inserted blocks match canonical Bitcoin data."}),"\n"]}),"\n"]}),"\n",(0,e.jsxs)(t.li,{children:["\n",(0,e.jsxs)(t.p,{children:["Run ",(0,e.jsx)(t.a,{href:"https://github.com/TheBestOrNothing/bitcoin-etl/blob/master/bitcoinetl/cli/clickhouse_transaction_hole_finding.py",children:(0,e.jsx)(t.code,{children:"clickhouse_transaction_hole_finding.py"})})]}),"\n",(0,e.jsxs)(t.ul,{children:["\n",(0,e.jsx)(t.li,{children:"Verify each block has its full set of transactions."}),"\n",(0,e.jsx)(t.li,{children:"Validate counts and structure."}),"\n"]}),"\n"]}),"\n",(0,e.jsxs)(t.li,{children:["\n",(0,e.jsxs)(t.p,{children:["Run ",(0,e.jsx)(t.a,{href:"https://github.com/TheBestOrNothing/bitcoin-etl/blob/master/bitcoinetl/cli/clickhouse_transaction_hole_fixing.py",children:(0,e.jsx)(t.code,{children:"clickhouse_transaction_hole_fixing.py"})})]}),"\n",(0,e.jsxs)(t.ul,{children:["\n",(0,e.jsx)(t.li,{children:"Backfill missing transactions."}),"\n",(0,e.jsx)(t.li,{children:"Re-index and refresh ClickHouse partitions."}),"\n"]}),"\n"]}),"\n",(0,e.jsxs)(t.li,{children:["\n",(0,e.jsxs)(t.p,{children:["Run ",(0,e.jsx)(t.code,{children:"OPTIMIZE TABLE"})," on each partition."]}),"\n",(0,e.jsxs)(t.ul,{children:["\n",(0,e.jsx)(t.li,{children:"Ensure ClickHouse merges and deduplicates entries efficiently."}),"\n"]}),"\n"]}),"\n",(0,e.jsxs)(t.li,{children:["\n",(0,e.jsxs)(t.p,{children:["Run ",(0,e.jsx)(t.a,{href:"https://github.com/TheBestOrNothing/bitcoin-etl/blob/master/bitcoinetl/cli/clickhouse_sync_data.py",children:(0,e.jsx)(t.code,{children:"clickhouse_sync_data.py"})})]}),"\n",(0,e.jsxs)(t.ul,{children:["\n",(0,e.jsxs)(t.li,{children:["Explode ",(0,e.jsx)(t.code,{children:"transactions_fat.inputs[]"})," into the ",(0,e.jsx)(t.code,{children:"inputs"})," table for a given partition."]}),"\n",(0,e.jsxs)(t.li,{children:["Explode ",(0,e.jsx)(t.code,{children:"transactions_fat.outputs[]"})," into placeholder rows in the ",(0,e.jsx)(t.code,{children:"outputs"})," table."]}),"\n",(0,e.jsxs)(t.li,{children:["Update ",(0,e.jsx)(t.code,{children:"outputs"})," with spent details by joining against ",(0,e.jsx)(t.code,{children:"inputs"}),"."]}),"\n"]}),"\n"]}),"\n"]}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,e.jsxs)(t.table,{children:[(0,e.jsx)(t.thead,{children:(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.th,{children:"Function"}),(0,e.jsx)(t.th,{children:"Purpose"})]})}),(0,e.jsxs)(t.tbody,{children:[(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"find_missing_block_partition"})}),(0,e.jsx)(t.td,{children:"Locate the partition immediately before the first missing block number."})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"get_block_partitions"})}),(0,e.jsxs)(t.td,{children:["Return a sorted list of distinct ",(0,e.jsx)(t.code,{children:"blocks_fat"})," partitions (YYYYMM)."]})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"check_partition_for_holes"})}),(0,e.jsxs)(t.td,{children:["Detect mismatches between ",(0,e.jsx)(t.code,{children:"blocks_fat.transactions"})," and ",(0,e.jsx)(t.code,{children:"transactions_fat"})," for one partition."]})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"final_transactions_fat"})}),(0,e.jsxs)(t.td,{children:["Run ",(0,e.jsx)(t.code,{children:"OPTIMIZE \u2026 FINAL"})," on a single ",(0,e.jsx)(t.code,{children:"transactions_fat"})," partition."]})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"populate_inputs"})}),(0,e.jsxs)(t.td,{children:["Explode ",(0,e.jsx)(t.code,{children:"transactions_fat.inputs[]"})," into the ",(0,e.jsx)(t.code,{children:"inputs"})," table for a given partition."]})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"populate_outputs"})}),(0,e.jsxs)(t.td,{children:["Explode ",(0,e.jsx)(t.code,{children:"transactions_fat.outputs[]"})," into placeholder rows in the ",(0,e.jsx)(t.code,{children:"outputs"})," table."]})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"populate_outputs_by_inputs"})}),(0,e.jsxs)(t.td,{children:["Update ",(0,e.jsx)(t.code,{children:"outputs"})," with spent details by joining against ",(0,e.jsx)(t.code,{children:"inputs"}),"."]})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"scan_for_transaction_holes"})}),(0,e.jsx)(t.td,{children:"Read-only sweep through partitions to find the first transaction hole."})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"scan_and_update"})}),(0,e.jsxs)(t.td,{children:["Full ETL loop: validate partitions then populate/repair ",(0,e.jsx)(t.code,{children:"inputs"})," and ",(0,e.jsx)(t.code,{children:"outputs"}),"."]})]}),(0,e.jsxs)(t.tr,{children:[(0,e.jsx)(t.td,{children:(0,e.jsx)(t.strong,{children:"main"})}),(0,e.jsxs)(t.td,{children:["CLI entry-point: parse ",(0,e.jsx)(t.code,{children:"--from_partition"})," and launch the scan-and-update workflow."]})]})]})]}),"\n",(0,e.jsx)(t.pre,{children:(0,e.jsx)(t.code,{className:"language-python",children:'import argparse\nimport clickhouse_connect\n\n# Example parameters\nhost = "localhost"\n# host = "192.168.2.242"\n# host = "host.docker.internal"\nport = 8123\nuser = "default"\npassword = "password"  # Empty by default\n# password = ""  # Empty by default\ndbname = "bitcoin"\n\nclient = clickhouse_connect.get_client(\n    host=host,\n    port=port,\n    username=user,\n    password=password,\n    database=dbname\n)\n\n# Run a test query\nresult = client.query("SELECT count() from blocks_fat")\nprint(result.result_rows)\n\ndef find_missing_block_partition(client):\n    """\n    Finds the first missing block number and its preceding partition.\n\n    Returns:\n        int or None: The YYYYMM of the partition before the missing block, or None if no missing block.\n    """\n    missing_block_query = """\n    WITH seq AS (\n        SELECT number\n        FROM numbers(\n            toUInt64(\n                ifNull((SELECT max(number) FROM blocks_fat), 0) + 1\n            )\n        )\n    )\n    SELECT min(seq.number) AS missing_block_number\n    FROM seq\n    LEFT ANTI JOIN blocks_fat AS b ON seq.number = b.number\n    """\n    result = client.query(missing_block_query).result_rows\n    if result and result[0][0] is not None:\n        missing_block = result[0][0]\n        print(\'missing_block\', missing_block)\n        block_before_missing = missing_block - 1\n        partition_query = f"""\n        SELECT toYYYYMM(timestamp_month)\n        FROM blocks_fat\n        WHERE number = {block_before_missing}\n        """\n        partition_result = client.query(partition_query).result_rows\n        return partition_result[0][0] if partition_result else None\n    return None\n\n\ndef get_block_partitions(client):\n    """\n    Queries all unique YYYYMM partitions from the `blocks_fat` table.\n    """\n    query = """\n        SELECT DISTINCT toYYYYMM(timestamp_month) AS part\n        FROM blocks_fat\n        ORDER BY part\n    """\n    partitions = client.query(query).result_rows\n    return [row[0] for row in partitions]\n\n\ndef check_partition_for_holes(partition: int, client):\n    """\n    Checks a specific partition for transaction mismatches.\n    Prints info if any mismatch is found.\n    """\n    block_tx_missing_query = f"""\n    WITH flattened AS (\n        SELECT\n            hash AS block_hash,\n            arrayJoin(transactions) AS tx_hash,\n            number As block_number\n        FROM blocks_fat \n        WHERE toYYYYMM(timestamp_month) = {partition}\n    )\n    SELECT\n        flattened.block_hash,\n        flattened.tx_hash,\n        flattened.block_number\n    FROM flattened\n    LEFT ANTI JOIN (\n        SELECT hash\n        FROM transactions_fat \n        WHERE toYYYYMM(block_timestamp_month) = {partition}\n    ) AS t\n    ON flattened.tx_hash = t.hash\n    """\n    missing_in_transactions = client.query(block_tx_missing_query).result_rows\n\n    tx_not_in_blocks_query = f"""\n    WITH flattened AS (\n        SELECT\n            hash AS block_hash,\n            arrayJoin(transactions) AS tx_hash\n        FROM blocks_fat \n        WHERE toYYYYMM(timestamp_month) = {partition}\n    )\n    SELECT\n        t.hash\n    FROM (\n        SELECT hash\n        FROM transactions_fat \n        WHERE toYYYYMM(block_timestamp_month) = {partition}\n    ) AS t\n    LEFT ANTI JOIN flattened\n    ON t.hash = flattened.tx_hash\n    """\n    missing_in_blocks = client.query(tx_not_in_blocks_query).result_rows\n\n    if missing_in_transactions:\n        print(f"\\n\u274C Partition {partition}: block.transactions missing in transactions_fat")\n        for row in missing_in_transactions:\n            print(f" - Transaction {row[1]} is in block {row[2]} but missing from transactions_fat")\n        return True\n\n    if missing_in_blocks:\n        print(f"\\n\u274C Partition {partition}: transactions_fat entries missing in block.transactions")\n        for row in missing_in_blocks:\n            print(f" - Transaction {row[0]} exists in transactions_fat but not in any blocks_fat.transactions")\n        return True\n\n    print(f"-- Partition {partition}: No transaction holes found")\n    return False\n\ndef final_transactions_fat(partition: int, client):\n    """\n    Optimizes the specified partition of the transactions_fat table using FINAL.\n\n    Args:\n        partition (int): The partition value in YYYYMM format (e.g., 202304).\n        client: ClickHouse client instance.\n    """\n    sql = f"OPTIMIZE TABLE transactions_fat PARTITION {partition} FINAL"\n    client.command(sql)\n    print(f"-- Optimizing transactions_fat partition {partition}...")\n\n\ndef populate_inputs(partition: int, client):\n    # Insert into inputs\n    insert_inputs_sql = f"""\n    INSERT INTO inputs\n    SELECT\n        t.hash AS transaction_hash,\n        input.1 AS input_index,\n        t.block_hash,\n        t.block_number,\n        t.block_timestamp,\n        input.2 AS spending_transaction_hash,\n        input.3 AS spending_output_index,\n        input.4 AS script_asm,\n        input.5 AS script_hex,\n        input.6 AS sequence,\n        input.7 AS required_signatures,\n        input.8 AS type,\n        input.9 AS addresses,\n        input.10 AS value\n    FROM (\n        SELECT\n            hash,\n            block_hash,\n            block_number,\n            block_timestamp,\n            inputs\n        FROM transactions_fat \n        WHERE toYYYYMM(block_timestamp) = {partition}\n    ) AS t\n    ARRAY JOIN t.inputs AS input\n    """\n    client.command(insert_inputs_sql)\n    print(f"-- Populating inputs for partition {partition}...")\n\n\ndef populate_outputs(partition: int, client):\n\n    # Insert into outputs (initial)\n    insert_outputs_sql = f"""\n    INSERT INTO outputs\n    SELECT\n        t.hash AS transaction_hash,\n        output.1 AS output_index,\n        t.block_hash,\n        t.block_number,\n        t.block_timestamp,\n        \'\' AS spent_transaction_hash,\n        0 AS spent_input_index,\n        \'\' AS spent_block_hash,\n        0 AS spent_block_number,\n        toDateTime(\'1970-01-01 00:00:00\') AS spent_block_timestamp,\n        output.2 AS script_asm,\n        output.3 AS script_hex,\n        output.4 AS required_signatures,\n        output.5 AS type,\n        output.6 AS addresses,\n        output.7 AS value\n    FROM (\n        SELECT\n            hash,\n            block_hash,\n            block_number,\n            block_timestamp,\n            outputs\n        FROM transactions_fat \n        WHERE toYYYYMM(block_timestamp) = {partition}\n    ) AS t\n    ARRAY JOIN t.outputs AS output\n    """\n    client.command(insert_outputs_sql)\n    print(f"-- Populating outputs for partition {partition}...")\n\ndef populate_outputs_by_inputs(partition: int, client):\n    # Finalize spent info update\n    insert_spent_sql = f"""\n    INSERT INTO outputs\n    SELECT\n        o.transaction_hash,\n        o.output_index,\n        o.block_hash,\n        o.block_number,\n        o.block_timestamp,\n        i.transaction_hash          AS spent_transaction_hash,\n        i.input_index               AS spent_input_index,\n        i.block_hash                AS spent_block_hash,\n        i.block_number              AS spent_block_number,\n        i.block_timestamp           AS spent_block_timestamp,\n        o.script_asm,\n        o.script_hex,\n        o.required_signatures,\n        o.type,\n        o.addresses,\n        o.value\n    FROM (\n        SELECT\n            transaction_hash,\n            input_index,\n            block_hash,\n            block_number,\n            block_timestamp,\n            spending_transaction_hash,\n            spending_output_index\n        FROM inputs \n        WHERE toYYYYMM(block_timestamp) = {partition}\n    ) AS i\n    INNER JOIN outputs AS o\n        ON i.spending_transaction_hash = o.transaction_hash\n    AND i.spending_output_index = o.output_index\n    """\n    client.command(insert_spent_sql)\n    print(f"-- Populating outputs by inputs for partition {partition}...")\n\n\ndef scan_for_transaction_holes(client, from_partition: int = None):\n    """\n    Scans all partitions up to the first block hole, checking for transaction holes.\n    Stops when the first transaction hole is found.\n    """\n    block_hole_partition = find_missing_block_partition(client)\n    all_partitions = get_block_partitions(client)\n\n    if block_hole_partition:\n        print(f"\uD83D\uDEA7 First block hole found in partition {block_hole_partition}")\n        partitions_to_check = [p for p in all_partitions if p <= block_hole_partition]\n    else:\n        print("\u2705 No block holes found \u2014 checking all partitions.")\n        partitions_to_check = all_partitions\n\n    # Apply from_partition filter\n    if from_partition:\n        partitions_to_check = [p for p in partitions_to_check if p >= from_partition]\n        print(f"\uD83D\uDD0D Scanning partitions from {from_partition} onwards...")\n\n    for partition in partitions_to_check:\n        if check_partition_for_holes(partition, client):\n            print(f"\u26D4 Stopping: transaction hole found in partition {partition}")\n            print(f"\uD83D\uDEA7 First block hole found in partition {block_hole_partition}")\n            return\n\n    print("\u2705 All checked partitions are transactionally consistent.")\n\ndef scan_and_update(client, from_partition: int = None):\n    """\n    Scans partitions for transaction holes and updates inputs and outputs tables.\n    """\n    block_hole_partition = find_missing_block_partition(client)\n    all_partitions = get_block_partitions(client)\n\n    if block_hole_partition:\n        print(f"\uD83D\uDEA7 First block hole found in partition {block_hole_partition}")\n        partitions_to_check = [p for p in all_partitions if p <= block_hole_partition]\n    else:\n        print("\u2705 No block holes found \u2014 checking all partitions.")\n        partitions_to_check = all_partitions\n\n    # Apply from_partition filter\n    if from_partition:\n        partitions_to_check = [p for p in partitions_to_check if p >= from_partition]\n        print(f"\uD83D\uDD0D Scanning partitions from {from_partition} onwards...")\n\n    for partition in partitions_to_check:\n        # final_transactions_fat(partition, client)\n\n        if check_partition_for_holes(partition, client):\n            print(f"\u26D4 Stopping: transaction hole found in partition {partition}")\n            print(f"\uD83D\uDEA7 First block hole found in partition {block_hole_partition}")\n            return\n\n        populate_inputs(partition, client)\n        populate_outputs(partition, client)\n        populate_outputs_by_inputs(partition, client)\n        print(f"\u2705 Partition {partition} is transactionally consistent and updated.")\n\n    print("\u2705 All checked partitions are transactionally consistent and updated.")\n\n\n#scan_for_transaction_holes(client)\n\ndef main():\n    parser = argparse.ArgumentParser(description="Scan ClickHouse partitions for Bitcoin transaction holes.")\n    parser.add_argument("--from_partition", type=int, help="Start scanning from this partition (inclusive), e.g., 201304")\n    args = parser.parse_args()\n\n    scan_and_update(client, from_partition=args.from_partition)\n    # scan_for_transaction_holes(client, from_partition=args.from_partition)\n\nif __name__ == "__main__":\n    main()\n'})})]})}function h(n={}){let{wrapper:t}={...(0,o.a)(),...n.components};return t?(0,e.jsx)(t,{...n,children:(0,e.jsx)(p,{...n})}):p(n)}},80980:function(n,t,i){i.d(t,{Z:()=>a,a:()=>r});var s=i(67294);let e={},o=s.createContext(e);function r(n){let t=s.useContext(o);return s.useMemo(function(){return"function"==typeof n?n(t):{...t,...n}},[t,n])}function a(n){let t;return t=n.disableParentContext?"function"==typeof n.components?n.components(e):n.components||e:r(n.components),s.createElement(o.Provider,{value:t},n.children)}}}]);