"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([["86663"],{57234:function(e,n,s){s.d(n,{Z:()=>t});let t=s.p+"assets/images/bitcoin_data_pipeline-083bc34cccd93411924337896b88770f.png"},94057:function(e,n,s){s.d(n,{Z:()=>t});let t=s.p+"assets/images/clickhouse-schema-evolution-8ce662ea09a5f64424f9178d22d19418.png"},42023:function(e,n,s){s.r(n),s.d(n,{frontMatter:()=>c,default:()=>h,contentTitle:()=>o,assets:()=>a,toc:()=>d,metadata:()=>t});var t=JSON.parse('{"id":"bitcoin/clickhouse-schema-evolution","title":"05 ClickHouse Schema Evolution","description":"To add new attributes (previousblockhash, transactions, and nTx) to a ClickHouse table using the Kafka engine\u2014assuming your existing table already receives streaming data from Kafka\u2014you must follow a safe schema evolution process due to ClickHouse\'s strict handling of schemas and its decoupled ingestion setup. Here\'s a professional, step-by-step guide as if taught by a professor of ClickHouse + Kafka streaming integration.","source":"@site/versioned_docs/version-3.7.1/bitcoin/clickhouse-schema-evolution.md","sourceDirName":"bitcoin","slug":"/bitcoin/clickhouse-schema-evolution","permalink":"/docs/bitcoin/clickhouse-schema-evolution","draft":false,"unlisted":false,"editUrl":"https://github.com/coinsgpt/coinsgpt.github.io/edit/main/website/docs/bitcoin/clickhouse-schema-evolution.md","tags":[],"version":"3.7.1","frontMatter":{},"sidebar":"bitcoin","previous":{"title":"04 ClickHouse Schema","permalink":"/docs/bitcoin/clickhouse-schema"},"next":{"title":"05 Kafka Table Engine","permalink":"/docs/bitcoin/kafka-table-engine"}}'),i=s(85893),l=s(80980);let c={},o="05 ClickHouse Schema Evolution",a={},d=[{value:"What You Have Now",id:"what-you-have-now",level:2},{value:"What You Want to Do",id:"what-you-want-to-do",level:2},{value:"Step 1: Stop the Kafka Producer",id:"step-1-stop-the-kafka-producer",level:2},{value:"Step 2: Detach the Materialized View (<code>blocks_mv</code>)",id:"step-2-detach-the-materialized-view-blocks_mv",level:2},{value:"Step 3: Update the Kafka Engine Table (<code>blocks_queue</code>)",id:"step-3-update-the-kafka-engine-table-blocks_queue",level:2},{value:"Step 4: Update the MergeTree Table (<code>blocks</code>)",id:"step-4-update-the-mergetree-table-blocks",level:2},{value:"Step 5: Drop the Old Materialized View (<code>blocks_mv</code>)",id:"step-5-drop-the-old-materialized-view-blocks_mv",level:2},{value:"Step 6: Recreate the Materialized View (<code>blocks_mv</code>)",id:"step-6-recreate-the-materialized-view-blocks_mv",level:2},{value:"Step 7: Resume the Kafka Producer",id:"step-7-resume-the-kafka-producer",level:2},{value:"Step 8: Validate End-to-End",id:"step-8-validate-end-to-end",level:2},{value:"\u2705 Summary: Schema Evolution Plan",id:"-summary-schema-evolution-plan",level:2}];function r(e){let n={blockquote:"blockquote",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,l.a)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"05-clickhouse-schema-evolution",children:"05 ClickHouse Schema Evolution"})}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:s(57234).Z+"",width:"1536",height:"1024"})}),"\n",(0,i.jsx)(n.p,{children:"To add new attributes (previousblockhash, transactions, and nTx) to a ClickHouse table using the Kafka engine\u2014assuming your existing table already receives streaming data from Kafka\u2014you must follow a safe schema evolution process due to ClickHouse's strict handling of schemas and its decoupled ingestion setup. Here's a professional, step-by-step guide as if taught by a professor of ClickHouse + Kafka streaming integration."}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Layer"}),(0,i.jsx)(n.th,{children:"Action"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Kafka Producer"}),(0,i.jsx)(n.td,{children:"Add the new fields to emitted JSON"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Kafka Engine Table"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"ALTER TABLE blocks_queue ADD COLUMN"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Materialized View"}),(0,i.jsxs)(n.td,{children:["Drop and recreate ",(0,i.jsx)(n.code,{children:"blocks_mv"})," with new SELECT clause"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Destination Table"}),(0,i.jsxs)(n.td,{children:["Add new fields using ",(0,i.jsx)(n.code,{children:"ALTER TABLE blocks ADD COLUMN"})]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Verification"}),(0,i.jsxs)(n.td,{children:["Use ",(0,i.jsx)(n.code,{children:"SELECT"})," queries to validate parsing"]})]})]})]}),"\n",(0,i.jsx)(n.p,{children:(0,i.jsx)(n.img,{src:s(94057).Z+"",width:"1536",height:"1024"})}),"\n",(0,i.jsxs)(n.p,{children:["In production systems, ",(0,i.jsx)(n.strong,{children:"graceful schema evolution"})," means:"]}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsx)(n.li,{children:(0,i.jsx)(n.strong,{children:"Pausing ingestion"})}),"\n",(0,i.jsx)(n.li,{children:"Updating schema"}),"\n",(0,i.jsx)(n.li,{children:"Restarting streaming with minimal data loss or duplication"}),"\n"]}),"\n",(0,i.jsxs)(n.p,{children:["Below is a ",(0,i.jsx)(n.strong,{children:"professor-level, zero-downtime-friendly guide"})," to ",(0,i.jsx)(n.strong,{children:"safely modify a Kafka-to-ClickHouse pipeline"})," using your components:"]}),"\n",(0,i.jsx)(n.h2,{id:"what-you-have-now",children:"What You Have Now"}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsxs)(n.li,{children:["Kafka Engine Table: ",(0,i.jsx)(n.code,{children:"blocks_queue"})]}),"\n",(0,i.jsxs)(n.li,{children:["Materialized View: ",(0,i.jsx)(n.code,{children:"blocks_mv"})]}),"\n",(0,i.jsxs)(n.li,{children:["Storage Table: ",(0,i.jsx)(n.code,{children:"blocks"})]}),"\n",(0,i.jsxs)(n.li,{children:["Kafka Producer: actively pushing JSON to topic ",(0,i.jsx)(n.code,{children:"blocks"})]}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"what-you-want-to-do",children:"What You Want to Do"}),"\n",(0,i.jsxs)(n.ol,{children:["\n",(0,i.jsxs)(n.li,{children:["Temporarily pause ingestion (",(0,i.jsx)(n.code,{children:"blocks_mv"})," consuming from ",(0,i.jsx)(n.code,{children:"blocks_queue"}),")"]}),"\n",(0,i.jsxs)(n.li,{children:["Add new columns to ",(0,i.jsx)(n.code,{children:"blocks_queue"}),", ",(0,i.jsx)(n.code,{children:"blocks"}),", and ",(0,i.jsx)(n.code,{children:"blocks_mv"})]}),"\n",(0,i.jsx)(n.li,{children:"Resume ingestion without data corruption"}),"\n"]}),"\n",(0,i.jsx)(n.hr,{}),"\n",(0,i.jsx)(n.h2,{id:"step-1-stop-the-kafka-producer",children:"Step 1: Stop the Kafka Producer"}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["Pause the source application producing data to the ",(0,i.jsx)(n.code,{children:"blocks"})," Kafka topic to prevent in-flight writes while you upgrade schema."]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Stop the producer app or its Kafka client (Ctrl + C)\npython3 bitcoinetl.py stream -p http://bitcoin:password@localhost:8332 --output kafka/localhost:9092 --period-seconds 0 -b 100 -B 1000 --log-file log --enrich True -l last_synced_block.txt\n"})}),"\n",(0,i.jsxs)(n.h2,{id:"step-2-detach-the-materialized-view-blocks_mv",children:["Step 2: Detach the Materialized View (",(0,i.jsx)(n.code,{children:"blocks_mv"}),")"]}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["This stops the automatic flow of data ",(0,i.jsxs)(n.strong,{children:["from Kafka to ",(0,i.jsx)(n.code,{children:"blocks"})]}),", but keeps all data in Kafka ",(0,i.jsx)(n.strong,{children:"unconsumed"}),"."]}),"\n"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"DETACH TABLE blocks_mv;\n"})}),"\n",(0,i.jsxs)(n.p,{children:["The view is paused, but the Kafka offsets in ",(0,i.jsx)(n.code,{children:"blocks_queue"})," are ",(0,i.jsx)(n.strong,{children:"not committed"}),". So when reattached, it picks up where it left off."]}),"\n",(0,i.jsxs)(n.h2,{id:"step-3-update-the-kafka-engine-table-blocks_queue",children:["Step 3: Update the Kafka Engine Table (",(0,i.jsx)(n.code,{children:"blocks_queue"}),")"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"ALTER TABLE blocks_queue\nADD COLUMN previousblockhash String;\n\nALTER TABLE blocks_queue\nADD COLUMN transactions Array(String);\n\nALTER TABLE blocks_queue\nADD COLUMN nTx UInt32;\n"})}),"\n",(0,i.jsxs)(n.blockquote,{children:["\n",(0,i.jsxs)(n.p,{children:["If unsure all messages will have these fields, use ",(0,i.jsx)(n.code,{children:"Nullable(...)"}),"."]}),"\n"]}),"\n",(0,i.jsxs)(n.h2,{id:"step-4-update-the-mergetree-table-blocks",children:["Step 4: Update the MergeTree Table (",(0,i.jsx)(n.code,{children:"blocks"}),")"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"ALTER TABLE blocks\nADD COLUMN previousblockhash String;\n\nALTER TABLE blocks\nADD COLUMN transactions Array(String);\n\nALTER TABLE blocks\nADD COLUMN nTx UInt32;\n"})}),"\n",(0,i.jsxs)(n.h2,{id:"step-5-drop-the-old-materialized-view-blocks_mv",children:["Step 5: Drop the Old Materialized View (",(0,i.jsx)(n.code,{children:"blocks_mv"}),")"]}),"\n",(0,i.jsxs)(n.p,{children:["You must ",(0,i.jsx)(n.strong,{children:"drop"})," (not alter) the materialized view to reflect the new columns."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"DROP TABLE blocks_mv;\n"})}),"\n",(0,i.jsxs)(n.h2,{id:"step-6-recreate-the-materialized-view-blocks_mv",children:["Step 6: Recreate the Materialized View (",(0,i.jsx)(n.code,{children:"blocks_mv"}),")"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"CREATE MATERIALIZED VIEW blocks_mv\nTO blocks\nAS\nSELECT\n    hash,\n    height,\n    version,\n    versionHex,\n    merkleroot,\n    time,\n    mediantime,\n    nonce,\n    bits,\n    difficulty,\n    chainwork,\n    previousblockhash,\n    transactions,\n    nTx\nFROM blocks_queue;\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-7-resume-the-kafka-producer",children:"Step 7: Resume the Kafka Producer"}),"\n",(0,i.jsxs)(n.p,{children:["Now that the pipeline is upgraded, ",(0,i.jsx)(n.strong,{children:"restart"})," the producer:"]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-bash",children:"# Restart your Kafka producer\npython3 bitcoinetl.py stream -p http://bitcoin:passw0rd@localhost:8332 --output kafka/localhost:9092 --period-seconds 0 -b 100 -B 1000 --log-file log --enrich True -l last_synced_block.txt\n"})}),"\n",(0,i.jsx)(n.h2,{id:"step-8-validate-end-to-end",children:"Step 8: Validate End-to-End"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-sql",children:"SELECT\n    hash,\n    previousblockhash,\n    nTx,\n    length(transactions) AS tx_count\nFROM blocks\nORDER BY height DESC\nLIMIT 10;\n"})}),"\n",(0,i.jsx)(n.p,{children:"Ensure everything flows correctly."}),"\n",(0,i.jsx)(n.h2,{id:"-summary-schema-evolution-plan",children:"\u2705 Summary: Schema Evolution Plan"}),"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Step"}),(0,i.jsx)(n.th,{children:"Action"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"1"}),(0,i.jsx)(n.td,{children:"Stop Kafka Producer"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"2"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"DETACH TABLE blocks_mv"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"3"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"ALTER TABLE blocks_queue"})," (add columns)"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"4"}),(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.code,{children:"ALTER TABLE blocks"})," (add columns)"]})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"5"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"DROP TABLE blocks_mv"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"6"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.code,{children:"CREATE MATERIALIZED VIEW blocks_mv"})})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"7"}),(0,i.jsx)(n.td,{children:"Restart Kafka Producer"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"8"}),(0,i.jsxs)(n.td,{children:["Validate new data in ",(0,i.jsx)(n.code,{children:"blocks"})]})]})]})]})]})}function h(e={}){let{wrapper:n}={...(0,l.a)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(r,{...e})}):r(e)}},80980:function(e,n,s){s.d(n,{Z:()=>o,a:()=>c});var t=s(67294);let i={},l=t.createContext(i);function c(e){let n=t.useContext(l);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:c(e.components),t.createElement(l.Provider,{value:n},e.children)}}}]);